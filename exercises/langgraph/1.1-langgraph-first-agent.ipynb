{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1.1: Building Your First Agent with LangGraph\n",
    "\n",
    "[![LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/)\n",
    "\n",
    "**Objective:** Build a complete StateGraph application from scratch\n",
    "\n",
    "In this exercise, you'll practice:\n",
    "- Defining state schemas with TypedDict\n",
    "- Implementing node functions that update state\n",
    "- Using normal and conditional edges\n",
    "- Compiling and testing a working graph\n",
    "\n",
    "<a target=\"_blank\" href=\"https://githubtocolab.com/IT-HUSET/ai-agenter-2025/blob/main/exercises/langgraph/1.1-langgraph-first-agent.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai~=2.0 --upgrade --quiet\n",
    "%pip install python-dotenv~=1.0 --upgrade --quiet\n",
    "%pip install langchain~=0.3 langchain_openai~=0.3 --upgrade --quiet\n",
    "%pip install langgraph~=0.6 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check if running in Google Colab\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    IN_COLAB = True\n",
    "    # Get API key from Colab secrets\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
    "    print(\"✅ Running in Google Colab - API key loaded from secrets\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    # Load from .env file for local development\n",
    "    try:\n",
    "        from dotenv import load_dotenv, find_dotenv\n",
    "        load_dotenv(find_dotenv())\n",
    "        print(\"✅ Running locally - API key loaded from .env file\")\n",
    "    except ImportError:\n",
    "        print(\"⚠️ python-dotenv not installed. Install with: pip install python-dotenv\")\n",
    "\n",
    "# Verify API key is set\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"❌ OPENAI_API_KEY not found!\")\n",
    "    if IN_COLAB:\n",
    "        print(\"   → Click the key icon (🔑) in the left sidebar\")\n",
    "        print(\"   → Add a secret named 'OPENAI_API_KEY'\")\n",
    "        print(\"   → Toggle 'Notebook access' to enable it\")\n",
    "    else:\n",
    "        print(\"   → Create a .env file with: OPENAI_API_KEY=your-key-here\")\n",
    "else:\n",
    "    print(\"✅ API key configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Understanding State and Nodes\n",
    "\n",
    "### State Schema with TypedDict\n",
    "\n",
    "LangGraph uses TypedDict to define the state schema. This provides type hints and structure while remaining a regular dict at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, NotRequired\n",
    "\n",
    "class NameGeneratorState(TypedDict):\n",
    "    \"\"\"State for our name generator agent.\n",
    "    \n",
    "    Fields:\n",
    "        original_name: The user's input name\n",
    "        cool_name: Generated cool version of the name (optional)\n",
    "        greeting: Final greeting message (optional)\n",
    "    \"\"\"\n",
    "    original_name: str\n",
    "    cool_name: NotRequired[str]  # Optional field\n",
    "    greeting: NotRequired[str]    # Optional field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Functions\n",
    "\n",
    "Nodes are Python functions that:\n",
    "1. Receive the current state as input\n",
    "2. Perform some computation\n",
    "3. Return a dict with state updates\n",
    "\n",
    "**Important:** By default, returned values OVERWRITE existing state values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cool_name(state: NameGeneratorState) -> NameGeneratorState:\n",
    "    \"\"\"Generate a cool version of the user's name using LLM.\"\"\"\n",
    "    print(\"---Generating Cool Name---\")\n",
    "    \n",
    "    original = state[\"original_name\"]\n",
    "    \n",
    "    prompt = f\"\"\"Generate a cool, creative variation of the name '{original}'. \n",
    "    Make it fun and memorable, but still recognizable. \n",
    "    Respond with ONLY the cool name, nothing else.\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    cool_name = response.content.strip()\n",
    "    \n",
    "    print(f\"Generated: {original} -> {cool_name}\")\n",
    "    \n",
    "    # Return dict with state updates\n",
    "    return {\"cool_name\": cool_name}\n",
    "\n",
    "\n",
    "def create_happy_greeting(state: NameGeneratorState) -> NameGeneratorState:\n",
    "    \"\"\"Create an enthusiastic greeting.\"\"\"\n",
    "    print(\"---Creating Happy Greeting---\")\n",
    "    \n",
    "    name = state[\"cool_name\"]\n",
    "    greeting = f\"🎉 Hey there, {name}! You're awesome! Have an amazing day! 🌟\"\n",
    "    \n",
    "    return {\"greeting\": greeting}\n",
    "\n",
    "\n",
    "def create_sad_greeting(state: NameGeneratorState) -> NameGeneratorState:\n",
    "    \"\"\"Create a melancholic greeting.\"\"\"\n",
    "    print(\"---Creating Sad Greeting---\")\n",
    "    \n",
    "    name = state[\"cool_name\"]\n",
    "    greeting = f\"😔 Oh... {name}... Life is so fleeting... Anyway, hi... 💔\"\n",
    "    \n",
    "    return {\"greeting\": greeting}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Individual Nodes\n",
    "\n",
    "Before building the graph, let's verify nodes work correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the name generator node\n",
    "test_state = {\"original_name\": \"Alice\"}\n",
    "result = generate_cool_name(test_state)\n",
    "print(f\"Result: {result}\")\n",
    "\n",
    "# Test greeting node\n",
    "test_state_2 = {\"original_name\": \"Alice\", \"cool_name\": \"Cosmic Alice\"}\n",
    "result_2 = create_happy_greeting(test_state_2)\n",
    "print(f\"\\nGreeting: {result_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Build the Graph\n",
    "\n",
    "### Conditional Edge Logic\n",
    "\n",
    "Conditional edges determine routing based on state. The function returns the name of the next node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "def decide_mood(state: NameGeneratorState) -> Literal[\"happy\", \"sad\"]:\n",
    "    \"\"\"Route based on name length - even = happy, odd = sad.\"\"\"\n",
    "    print(\"---Deciding Mood---\")\n",
    "    \n",
    "    name_length = len(state[\"cool_name\"])\n",
    "    \n",
    "    if name_length % 2 == 0:\n",
    "        print(f\"Name length {name_length} is even -> Happy!\")\n",
    "        return \"happy\"\n",
    "    else:\n",
    "        print(f\"Name length {name_length} is odd -> Sad...\")\n",
    "        return \"sad\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the Graph\n",
    "\n",
    "Now we'll build the complete workflow:\n",
    "\n",
    "1. **START** → Generate cool name\n",
    "2. Check name length (conditional edge)\n",
    "3. Route to either happy or sad greeting\n",
    "4. **END**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Initialize graph builder\n",
    "builder = StateGraph(NameGeneratorState)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"generate\", generate_cool_name)\n",
    "builder.add_node(\"happy\", create_happy_greeting)\n",
    "builder.add_node(\"sad\", create_sad_greeting)\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(START, \"generate\")\n",
    "\n",
    "# Conditional edge: route based on name length\n",
    "builder.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    decide_mood,\n",
    "    {\n",
    "        \"happy\": \"happy\",\n",
    "        \"sad\": \"sad\"\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_edge(\"happy\", END)\n",
    "builder.add_edge(\"sad\", END)\n",
    "\n",
    "# Compile the graph\n",
    "graph = builder.compile()\n",
    "\n",
    "# Visualize\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Test and Iterate\n",
    "\n",
    "### Invoke the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with different names\n",
    "test_names = [\"Alice\", \"Bob\", \"Charlie\", \"Diana\"]\n",
    "\n",
    "for name in test_names:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing with: {name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    result = graph.invoke({\"original_name\": name})\n",
    "    \n",
    "    print(f\"\\n✨ Final State:\")\n",
    "    print(f\"   Original: {result['original_name']}\")\n",
    "    print(f\"   Cool Name: {result['cool_name']}\")\n",
    "    print(f\"   Greeting: {result['greeting']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream the Graph (Optional)\n",
    "\n",
    "See each step of execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n🔄 Streaming execution:\\n\")\n",
    "\n",
    "for chunk in graph.stream({\"original_name\": \"Emma\"}):\n",
    "    print(f\"Step: {chunk}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🎯 Exercise: Build Your Own Graph!\n",
    "\n",
    "**Challenge:** Create a \"Job Title Generator\" that:\n",
    "\n",
    "1. Takes a person's hobby as input\n",
    "2. Generates a creative job title based on the hobby\n",
    "3. Routes based on title coolness:\n",
    "   - If title contains \"Chief\" or \"Wizard\" → enthusiastic response\n",
    "   - Otherwise → standard response\n",
    "4. Returns final message\n",
    "\n",
    "### Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATE\n",
    "class JobTitleState(TypedDict):\n",
    "    hobby: str\n",
    "    job_title: NotRequired[str]\n",
    "    response: NotRequired[str]\n",
    "\n",
    "# NODES\n",
    "def generate_job_title(state: JobTitleState) -> JobTitleState:\n",
    "    print(\"---Generating Job Title---\")\n",
    "    # TODO: Use LLM to generate creative job title from hobby\n",
    "    # Example prompt: \"Create a creative, fun job title for someone whose hobby is {hobby}\"\n",
    "    return {\"job_title\": \"TODO\"}\n",
    "\n",
    "def enthusiastic_response(state: JobTitleState) -> JobTitleState:\n",
    "    print(\"---Enthusiastic Response---\")\n",
    "    # TODO: Create enthusiastic message\n",
    "    return {\"response\": \"TODO\"}\n",
    "\n",
    "def standard_response(state: JobTitleState) -> JobTitleState:\n",
    "    print(\"---Standard Response---\")\n",
    "    # TODO: Create standard message\n",
    "    return {\"response\": \"TODO\"}\n",
    "\n",
    "# CONDITIONAL EDGE\n",
    "def check_coolness(state: JobTitleState) -> Literal[\"enthusiastic\", \"standard\"]:\n",
    "    # TODO: Check if title contains \"Chief\" or \"Wizard\"\n",
    "    title = state[\"job_title\"].lower()\n",
    "    if \"chief\" in title or \"wizard\" in title:\n",
    "        return \"enthusiastic\"\n",
    "    return \"standard\"\n",
    "\n",
    "# GRAPH\n",
    "# TODO: Build the graph\n",
    "# builder_exercise = StateGraph(JobTitleState)\n",
    "# ...\n",
    "# graph_exercise = builder_exercise.compile()\n",
    "\n",
    "# Test it!\n",
    "# result = graph_exercise.invoke({\"hobby\": \"gardening\"})\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "✅ **State Schema**: Use TypedDict to define structured state  \n",
    "✅ **Nodes**: Python functions that receive state and return updates  \n",
    "✅ **Edges**: Connect nodes (normal or conditional)  \n",
    "✅ **Conditional Logic**: Route based on state values  \n",
    "✅ **Compilation**: Always compile before using the graph  \n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Module 1.7: LLM-based routing for dynamic decision making\n",
    "- Module 1.8: Tool calling with ReAct pattern\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [LangGraph Low-Level Concepts](https://langchain-ai.github.io/langgraph/concepts/low_level/)\n",
    "- [StateGraph Documentation](https://langchain-ai.github.io/langgraph/concepts/low_level/#stategraph)\n",
    "- [LangGraph Tutorials](https://langchain-ai.github.io/langgraph/tutorials/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agents-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
