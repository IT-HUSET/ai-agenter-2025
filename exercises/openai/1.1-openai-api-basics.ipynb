{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 OpenAI API Basics\n",
    "\n",
    "This notebook covers the **foundational OpenAI APIs** for building AI applications:\n",
    "\n",
    "1. **Chat Completions API**: The traditional API with manual conversation management\n",
    "2. **Responses API**: The newer, stateful API (released March 2025)\n",
    "\n",
    "Understanding both APIs will help you:\n",
    "- Choose the right tool for your use case\n",
    "- Understand how AI agents manage state\n",
    "- Work with existing codebases using either API\n",
    "\n",
    "<a target=\"_blank\" href=\"https://githubtocolab.com/IT-HUSET/ai-agenter-2025/blob/main/exercises/openai/1.1-openai-api-basics.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai~=2.1 python-dotenv~=1.0 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport json\nfrom openai import OpenAI\n\n# Check if running in Google Colab\ntry:\n    from google.colab import userdata\n    IN_COLAB = True\n    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n    print(\"‚úÖ Running in Google Colab - API key loaded from secrets\")\nexcept ImportError:\n    IN_COLAB = False\n    try:\n        from dotenv import load_dotenv, find_dotenv\n        load_dotenv(find_dotenv())\n        print(\"‚úÖ Running locally - API key loaded from .env file\")\n    except ImportError:\n        print(\"‚ö†Ô∏è python-dotenv not installed\")\n\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\nif not os.getenv(\"OPENAI_API_KEY\"):\n    print(\"‚ùå OPENAI_API_KEY not found!\")\n    if IN_COLAB:\n        print(\"   ‚Üí Click the key icon (üîë) in the left sidebar and add 'OPENAI_API_KEY'\")\nelse:\n    print(\"‚úÖ OpenAI client initialized\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Chat Completions API - The Foundation\n",
    "\n",
    "The **Chat Completions API** is the traditional way to interact with OpenAI models.\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Messages**: Conversation is a list of messages with roles\n",
    "- **Roles**: `system`, `user`, `assistant`, `tool`\n",
    "- **Manual State**: You manage conversation history yourself\n",
    "\n",
    "**Why learn this?**\n",
    "- Used in most existing codebases\n",
    "- Fine-grained control over conversation\n",
    "- Essential for understanding agent architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Message Roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple request with Chat Completions API\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What is 2+2?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Response:\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Three Core Roles\n",
    "\n",
    "1. **`system`**: Sets behavior and instructions (typically placed first)\n",
    "2. **`user`**: User's input or questions\n",
    "3. **`assistant`**: Model's responses (in history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using system message to set behavior\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant who always responds in rhyme.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me about Python programming\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"With system message:\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Role Hierarchy in Chat Completions API\n",
    "\n",
    "The Chat Completions API uses three primary roles:\n",
    "\n",
    "**Role Priority & Purpose:**\n",
    "- **`system`**: High-level, persistent behavior instructions (highest priority)\n",
    "- **`user`**: User's input or questions\n",
    "- **`assistant`**: Model's responses (in conversation history)\n",
    "\n",
    "**Best Practice:**\n",
    "```python\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful coding assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"How do I read a file in Python?\"}\n",
    "]\n",
    "```\n",
    "\n",
    "**Note:** The `system` role provides persistent instructions throughout the conversation. Unlike the Responses API (covered in Part 2), Chat Completions API uses `system`, `user`, `assistant`, and `tool` roles only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using system role for persistent instructions\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are a helpful coding assistant. \n",
    "            When answering questions:\n",
    "            1. Prefer concise answers with code examples\n",
    "            2. Assume the user is using Python 3.12\n",
    "            3. Include brief explanations\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How do I use match-case statements?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"With detailed system instructions:\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison: basic vs detailed system instructions\n",
    "print(\"Basic system instruction:\")\n",
    "print(\"=\"*80)\n",
    "response_basic = client.chat.completions.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain classes in Python\"}\n",
    "    ]\n",
    ")\n",
    "print(response_basic.choices[0].message.content)\n",
    "\n",
    "print(\"\\n\\nDetailed system instruction:\")\n",
    "print(\"=\"*80)\n",
    "response_detailed = client.chat.completions.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"\"\"You are a helpful assistant. When explaining programming concepts:\n",
    "            1. Use simple language (ELI15 level)\n",
    "            2. Include a real-world analogy\n",
    "            3. Provide one code example\n",
    "            Keep total response under 100 words.\"\"\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"Explain classes in Python\"}\n",
    "    ]\n",
    ")\n",
    "print(response_detailed.choices[0].message.content)\n",
    "\n",
    "print(\"\\n\\nüí° More detailed system instructions provide better control over output format and style!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Conversation History Management\n",
    "\n",
    "Unlike the Responses API, you must **manually track** the conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a system message\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful Python expert.\"}\n",
    "]\n",
    "\n",
    "# Turn 1: User asks a question\n",
    "messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"How do I read a CSV file in Python?\"\n",
    "})\n",
    "\n",
    "response_1 = client.chat.completions.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# Add assistant's response to history\n",
    "assistant_message_1 = response_1.choices[0].message.content\n",
    "messages.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": assistant_message_1\n",
    "})\n",
    "\n",
    "print(\"Turn 1:\")\n",
    "print(assistant_message_1)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Turn 2: Follow-up question (requires context)\n",
    "messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"What if the file has headers?\"\n",
    "})\n",
    "\n",
    "response_2 = client.chat.completions.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "assistant_message_2 = response_2.choices[0].message.content\n",
    "print(\"Turn 2 (knows we're talking about CSV):\")\n",
    "print(assistant_message_2)\n",
    "\n",
    "# Inspect the full message history\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(f\"Total messages in history: {len(messages)}\")\n",
    "for i, msg in enumerate(messages):\n",
    "    print(f\"{i+1}. {msg['role']}: {msg['content'][:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Manager Pattern\n",
    "\n",
    "A common pattern is to create a helper class for managing conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatCompletionsConversation:\n",
    "    \"\"\"Helper class for managing Chat Completions API conversations\"\"\"\n",
    "    \n",
    "    def __init__(self, system_message: str = None, model: str = \"gpt-5-mini\"):\n",
    "        self.model = model\n",
    "        self.messages = []\n",
    "        \n",
    "        if system_message:\n",
    "            self.messages.append({\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_message\n",
    "            })\n",
    "    \n",
    "    def send(self, user_message: str, **kwargs) -> str:\n",
    "        \"\"\"Send a user message and get response\"\"\"\n",
    "        # Add user message to history\n",
    "        self.messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_message\n",
    "        })\n",
    "        \n",
    "        # Get completion\n",
    "        response = client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=self.messages,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        # Add assistant response to history\n",
    "        assistant_message = response.choices[0].message.content\n",
    "        self.messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": assistant_message\n",
    "        })\n",
    "        \n",
    "        return assistant_message\n",
    "    \n",
    "    def get_history(self) -> list:\n",
    "        \"\"\"Get full conversation history\"\"\"\n",
    "        return self.messages\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Clear conversation history (keeps system message)\"\"\"\n",
    "        system_messages = [msg for msg in self.messages if msg[\"role\"] == \"system\"]\n",
    "        self.messages = system_messages\n",
    "\n",
    "# Test the conversation manager\n",
    "conv = ChatCompletionsConversation(\n",
    "    system_message=\"You are a concise coding assistant. Keep answers under 50 words.\"\n",
    ")\n",
    "\n",
    "print(\"Turn 1:\")\n",
    "print(conv.send(\"What's a list comprehension in Python?\"))\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"Turn 2:\")\n",
    "print(conv.send(\"Show me an example\"))\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(f\"\\nConversation has {len(conv.get_history())} messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Exercise 1: Build a Conversation Manager\n",
    "\n",
    "**Task:** Enhance the `ChatCompletionsConversation` class:\n",
    "1. Add a `token_limit` parameter\n",
    "2. Implement automatic trimming when approaching the limit\n",
    "3. Keep system message and most recent N messages\n",
    "4. Test with a long conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "class SmartConversation(ChatCompletionsConversation):\n",
    "    \"\"\"Conversation manager with token limit handling\"\"\"\n",
    "    \n",
    "    def __init__(self, system_message: str = None, model: str = \"gpt-5-mini\", max_messages: int = 20):\n",
    "        super().__init__(system_message, model)\n",
    "        self.max_messages = max_messages\n",
    "    \n",
    "    def send(self, user_message: str, **kwargs) -> str:\n",
    "        # TODO: Implement trimming logic before sending\n",
    "        pass\n",
    "\n",
    "# Test your implementation\n",
    "# smart_conv = SmartConversation(max_messages=5)\n",
    "# for i in range(10):\n",
    "#     print(f\"Turn {i+1}: {smart_conv.send(f'Tell me fact #{i+1} about Python')}\")\n",
    "# print(f\"\\nFinal message count: {len(smart_conv.get_history())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Responses API - Modern Approach\n",
    "\n",
    "The **Responses API** (released March 2025) simplifies conversation management.\n",
    "\n",
    "**Key Differences:**\n",
    "- ‚úÖ **Stateful**: Conversation history managed automatically\n",
    "- ‚úÖ **Simpler**: No need to track messages manually\n",
    "- ‚úÖ **Built-in tools**: Native web search, file search\n",
    "- ‚úÖ **Multimodal**: Easy image/audio support\n",
    "\n",
    "**When to use which?**\n",
    "- **Chat Completions**: Fine-grained control, existing codebases\n",
    "- **Responses API**: New projects, simpler state management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Responses API Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple request - much cleaner!\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=\"What is 2+2?\"\n",
    ")\n",
    "\n",
    "print(\"Response:\")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Instructions with Responses API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System-level instructions (equivalent to system message)\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    instructions=\"You are a helpful assistant who always responds in rhyme.\",\n",
    "    input=\"Tell me about Python programming\"\n",
    ")\n",
    "\n",
    "print(\"With instructions:\")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Conversation History\n",
    "\n",
    "The key advantage of Responses API is automatic state management via `previous_response_id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn 1: Ask a question\n",
    "response_1 = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=\"How do I read a CSV file in Python?\"\n",
    ")\n",
    "\n",
    "print(\"Turn 1:\")\n",
    "print(response_1.output_text)\n",
    "print(f\"\\nResponse ID: {response_1.id}\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Turn 2: Follow-up (just reference previous response)\n",
    "response_2 = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=\"What if the file has headers?\",\n",
    "    previous_response_id=response_1.id  # ‚ú® Magic! History managed for you\n",
    ")\n",
    "\n",
    "print(\"Turn 2 (automatically knows context):\")\n",
    "print(response_2.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Comparison: Key Differences\n",
    "\n",
    "**Roles:**\n",
    "- **Chat Completions**: `system`, `user`, `assistant`, `tool`\n",
    "- **Responses API**: `developer`, `user`, `assistant` (+ `instructions` parameter)\n",
    "\n",
    "**State Management:**\n",
    "- **Chat Completions**: Manual (you manage message array)\n",
    "- **Responses API**: Automatic (via `previous_response_id`)\n",
    "\n",
    "**Instructions:**\n",
    "- **Chat Completions**: `system` role message\n",
    "- **Responses API**: `instructions` parameter OR `developer` role message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CHAT COMPLETIONS API:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "# Manual state management with system role\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are helpful\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello\"}\n",
    "]\n",
    "response = client.chat.completions.create(model=\"gpt-5-mini\", messages=messages)\n",
    "\n",
    "# Manually append assistant response\n",
    "messages.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
    "\n",
    "# Manually append next user message\n",
    "messages.append({\"role\": \"user\", \"content\": \"Follow-up\"})\n",
    "response = client.chat.completions.create(model=\"gpt-5-mini\", messages=messages)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nRESPONSES API:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "# Automatic state management with instructions parameter\n",
    "response_1 = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    instructions=\"You are helpful\",  # or use developer role in input\n",
    "    input=\"Hello\"\n",
    ")\n",
    "\n",
    "# Just reference previous response - history managed automatically!\n",
    "response_2 = client.responses.create(\n",
    "    model=\"gpt-5-mini\", \n",
    "    input=\"Follow-up\", \n",
    "    previous_response_id=response_1.id\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n‚úÖ Responses API = Less boilerplate, automatic state management, developer/user role hierarchy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Exercise 2: Convert to Responses API\n",
    "\n",
    "**Task:** Take your `ChatCompletionsConversation` class and convert it to use the Responses API instead.\n",
    "\n",
    "**Hints:**\n",
    "1. Store `previous_response_id` instead of messages array\n",
    "2. Use `instructions` parameter for system message\n",
    "3. The code should be simpler!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "class ResponsesConversation:\n",
    "    \"\"\"Helper class for managing Responses API conversations\"\"\"\n",
    "    \n",
    "    def __init__(self, instructions: str = None, model: str = \"gpt-5-mini\"):\n",
    "        self.model = model\n",
    "        self.instructions = instructions\n",
    "        self.previous_response_id = None\n",
    "    \n",
    "    def send(self, user_input: str, **kwargs) -> str:\n",
    "        \"\"\"Send a user message and get response\"\"\"\n",
    "        # TODO: Implement using Responses API\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset conversation\"\"\"\n",
    "        self.previous_response_id = None\n",
    "\n",
    "# Test your implementation\n",
    "# conv = ResponsesConversation(instructions=\"You are a helpful assistant\")\n",
    "# print(conv.send(\"What's a decorator in Python?\"))\n",
    "# print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "# print(conv.send(\"Show me an example\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "‚úÖ **Chat Completions API**: Manual history, role system, fine-grained control  \n",
    "‚úÖ **Responses API**: Automatic state management, simpler code  \n",
    "‚úÖ **When to use which**: Chat Completions for control, Responses for simplicity\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Chat Completions requires manual message tracking (more control)\n",
    "- Responses API handles state automatically (simpler)\n",
    "- Both APIs can accomplish the same tasks, just with different patterns\n",
    "\n",
    "**Next Steps:**\n",
    "- **Notebook 1.2**: Advanced OpenAI features (function calling, reasoning modes, model selection)\n",
    "- **Notebook 1.3**: Structured outputs with JSON schemas\n",
    "- **Notebook 1.4**: Prompt engineering techniques\n",
    "\n",
    "**Resources:**\n",
    "- [Chat Completions API Docs](https://platform.openai.com/docs/api-reference/chat)\n",
    "- [Responses API Docs](https://platform.openai.com/docs/api-reference/responses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}