{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Prompt Engineering - Essential TechniquesThis notebook covers **core prompt engineering techniques** for AI applications:- **Chain-of-Thought (CoT)**: Encouraging step-by-step reasoning- **ReAct Pattern**: Combining Reasoning and Action- **Few-Shot Learning**: Learning from examples- **Delimiters & Structure**: Organizing prompts for clarity- **Prompt Chaining**: Breaking complex tasks into stepsThese patterns are fundamental to building effective AI applications.<a target=\"_blank\" href=\"https://githubtocolab.com/IT-HUSET/ai-agenter-2025/blob/main/exercises/openai/1.4-prompt-engineering.ipynb\">  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai~=2.1 python-dotenv~=1.0 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom openai import OpenAI\n\n# Check if running in Google Colab\ntry:\n    from google.colab import userdata\n    IN_COLAB = True\n    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n    print(\"✅ Running in Google Colab - API key loaded from secrets\")\nexcept ImportError:\n    IN_COLAB = False\n    try:\n        from dotenv import load_dotenv, find_dotenv\n        load_dotenv(find_dotenv())\n        print(\"✅ Running locally - API key loaded from .env file\")\n    except ImportError:\n        print(\"⚠️ python-dotenv not installed\")\n\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\nif not os.getenv(\"OPENAI_API_KEY\"):\n    print(\"❌ OPENAI_API_KEY not found!\")\n    if IN_COLAB:\n        print(\"   → Click the key icon (🔑) in the left sidebar and add 'OPENAI_API_KEY'\")\nelse:\n    print(\"✅ Setup complete\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Chain-of-Thought (CoT) Prompting\n",
    "\n",
    "**Problem**: LLMs sometimes jump to conclusions without showing their work.\n",
    "\n",
    "**Solution**: Explicitly ask the model to \"think step by step\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct question - no reasoning shown\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=\"What is 47 × 23?\"\n",
    ")\n",
    "\n",
    "print(\"Without CoT:\")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoT prompt - shows reasoning\n",
    "cot_prompt = \"\"\"Calculate 47 × 23. Show your step-by-step reasoning:\n",
    "\n",
    "Step 1: Break down the multiplication\n",
    "Step 2: Calculate partial products\n",
    "Step 3: Sum the results\n",
    "Step 4: State the final answer\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=cot_prompt\n",
    ")\n",
    "\n",
    "print(\"With CoT:\")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoT for Complex Problems\n",
    "\n",
    "CoT is especially powerful for:\n",
    "- Math problems\n",
    "- Logic puzzles\n",
    "- Multi-step reasoning\n",
    "- Debugging code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = \"\"\"A train leaves Station A at 2:00 PM traveling at 60 mph. \n",
    "Another train leaves Station B (180 miles away) at 3:00 PM traveling at 90 mph toward Station A.\n",
    "At what time will they meet?\n",
    "\n",
    "Think through this step by step:\n",
    "1. Calculate distance traveled by first train before second train starts\n",
    "2. Calculate remaining distance between trains when both are moving\n",
    "3. Calculate combined speed\n",
    "4. Calculate time to meet\n",
    "5. Determine the meeting time\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=problem,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎯 Exercise 1: Practice CoT\n",
    "\n",
    "**Task:** Use CoT to solve this problem:\n",
    "\n",
    "> \"A farmer has chickens and rabbits. There are 35 heads and 94 legs total. How many chickens and how many rabbits?\"\n",
    "\n",
    "**Hint:** Structure your prompt to guide the model through:\n",
    "1. Define variables\n",
    "2. Set up equations\n",
    "3. Solve the system\n",
    "4. Verify the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "cot_problem = \"\"\"TODO: Write your CoT prompt\"\"\"\n",
    "\n",
    "# response = client.responses.create(\n",
    "#     model=\"gpt-5-mini\",\n",
    "#     input=cot_problem,\n",
    "#     temperature=0\n",
    "# )\n",
    "# print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: ReAct Pattern (Reason + Act)\n",
    "\n",
    "**ReAct** combines reasoning with action. It's the foundation of most agent frameworks.\n",
    "\n",
    "**Pattern:**\n",
    "```\n",
    "Thought: What do I need to do?\n",
    "Action: call_tool(params)\n",
    "Observation: Result from tool\n",
    "Thought: What does this mean?\n",
    "Answer: Final response\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple ReAct Example\n",
    "\n",
    "Let's implement a basic ReAct loop manually (before using frameworks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Fake weather API\"\"\"\n",
    "    weather_data = {\n",
    "        \"Stockholm\": \"5°C, cloudy, 80% chance of rain\",\n",
    "        \"London\": \"8°C, foggy\",\n",
    "        \"Paris\": \"10°C, sunny\",\n",
    "        \"Tokyo\": \"15°C, clear\"\n",
    "    }\n",
    "    return weather_data.get(city, \"Weather data not available\")\n",
    "\n",
    "# Test it\n",
    "print(get_weather(\"Stockholm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReAct prompt that encourages the pattern\n",
    "react_prompt = \"\"\"You are a helpful assistant that can check the weather.\n",
    "\n",
    "When answering questions, follow this pattern:\n",
    "1. Thought: Analyze what you need to do\n",
    "2. Action: Specify if you need to use the get_weather tool\n",
    "3. Answer: Provide the final response\n",
    "\n",
    "Available tool:\n",
    "- get_weather(city: str) -> str: Returns weather for a city\n",
    "\n",
    "Question: What's the weather like in Stockholm and should I bring an umbrella?\n",
    "\n",
    "Let's think step by step:\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=react_prompt,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual ReAct Loop\n",
    "\n",
    "Let's implement the loop manually to understand how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_react_loop(question: str, max_iterations=3):\n",
    "    \"\"\"Manual implementation of ReAct pattern\"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"You are a helpful assistant with access to tools.\n",
    "\n",
    "Follow this pattern:\n",
    "Thought: [your reasoning]\n",
    "Action: [tool_name(parameters)] OR Answer: [final answer]\n",
    "    \n",
    "Available tools:\n",
    "- get_weather(city: str): Get weather for a city\n",
    "\n",
    "Always show your thought process. When you have enough information, provide a final Answer.\n",
    "\"\"\"\n",
    "    \n",
    "    conversation = f\"{system_prompt}\\n\\nQuestion: {question}\\n\\n\"\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        print(f\"\\n--- Iteration {iteration + 1} ---\\n\")\n",
    "        \n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-5-mini\",\n",
    "            input=conversation,\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        output = response.output_text\n",
    "        print(output)\n",
    "        \n",
    "        # Check if we have a final answer\n",
    "        if \"Answer:\" in output:\n",
    "            print(\"\\n✅ Agent reached final answer\")\n",
    "            return output\n",
    "        \n",
    "        # Extract action (simplified parsing)\n",
    "        if \"get_weather(\" in output:\n",
    "            # Parse the city (very simplified)\n",
    "            import re\n",
    "            match = re.search(r'get_weather\\([\"\\']([^\"\\']+)[\"\\']\\)', output)\n",
    "            if match:\n",
    "                city = match.group(1)\n",
    "                weather = get_weather(city)\n",
    "                observation = f\"\\nObservation: {weather}\\n\"\n",
    "                print(observation)\n",
    "                conversation += output + observation\n",
    "            else:\n",
    "                print(\"\\n❌ Could not parse action\")\n",
    "                break\n",
    "        else:\n",
    "            conversation += output\n",
    "    \n",
    "    return conversation\n",
    "\n",
    "# Test it\n",
    "result = manual_react_loop(\"Compare the weather in Stockholm and Paris. Which city is warmer?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎯 Exercise 2: Implement ReAct\n",
    "\n",
    "**Task:** Create a ReAct agent that can use multiple tools:\n",
    "- `get_temperature(city)`: Returns temperature only\n",
    "- `get_population(city)`: Returns city population\n",
    "- `calculate(expression)`: Evaluates math expressions\n",
    "\n",
    "**Question:** \"What's the average temperature between Stockholm and Tokyo, and what's their combined population?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Define tools\n",
    "def get_temperature(city: str) -> float:\n",
    "    temps = {\"Stockholm\": 5, \"Tokyo\": 15, \"Paris\": 10, \"London\": 8}\n",
    "    return temps.get(city, 0)\n",
    "\n",
    "def get_population(city: str) -> int:\n",
    "    pops = {\"Stockholm\": 975000, \"Tokyo\": 14000000, \"Paris\": 2161000, \"London\": 9000000}\n",
    "    return pops.get(city, 0)\n",
    "\n",
    "def calculate(expression: str) -> float:\n",
    "    try:\n",
    "        return eval(expression, {\"__builtins__\": {}}, {})\n",
    "    except:\n",
    "        return \"Error\"\n",
    "\n",
    "# TODO: Implement a ReAct loop that can use these tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Few-Shot Learning\n",
    "\n",
    "**Few-shot learning**: Provide examples to guide the model's behavior.\n",
    "\n",
    "**When to use:**\n",
    "- Teaching new patterns or formats\n",
    "- Establishing consistent style or tone\n",
    "- Complex tasks that benefit from examples\n",
    "- Domain-specific outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-Shot vs Few-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot: No examples\n",
    "zero_shot = \"\"\"Classify the sentiment of this review as Positive, Negative, or Neutral:\n",
    "\n",
    "Review: \"The product works okay, but the packaging was damaged.\"\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=zero_shot,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(\"Zero-shot:\")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot: With examples\n",
    "few_shot = \"\"\"Classify the sentiment of reviews as Positive, Negative, or Neutral:\n",
    "\n",
    "Review: \"Absolutely amazing! Best purchase ever.\"\n",
    "Sentiment: Positive\n",
    "\n",
    "Review: \"Terrible quality, broke after one day.\"\n",
    "Sentiment: Negative\n",
    "\n",
    "Review: \"It's fine, nothing special.\"\n",
    "Sentiment: Neutral\n",
    "\n",
    "Review: \"The product works okay, but the packaging was damaged.\"\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=few_shot,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(\"Few-shot:\")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-Shot for Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_structured = \"\"\"Extract entities from text and return as JSON:\n",
    "\n",
    "Text: \"Apple announced the iPhone 15 at their Cupertino headquarters.\"\n",
    "Output: {\"company\": \"Apple\", \"product\": \"iPhone 15\", \"location\": \"Cupertino\"}\n",
    "\n",
    "Text: \"Microsoft's CEO Satya Nadella spoke at the conference in Seattle.\"\n",
    "Output: {\"company\": \"Microsoft\", \"person\": \"Satya Nadella\", \"location\": \"Seattle\"}\n",
    "\n",
    "Text: \"Tesla is building a new factory in Austin, Texas for the Cybertruck.\"\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=few_shot_structured,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎯 Exercise 3: Few-Shot for Code Generation\n",
    "\n",
    "**Task:** Use few-shot learning to generate SQL queries from natural language.\n",
    "\n",
    "Provide 2-3 examples, then test with a new query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "sql_prompt = \"\"\"Convert natural language to SQL:\n",
    "\n",
    "Database schema:\n",
    "- users (id, name, email, created_at)\n",
    "- orders (id, user_id, total, order_date)\n",
    "\n",
    "TODO: Add 2-3 examples here\n",
    "\n",
    "Question: \"Find all users who made an order in the last 30 days\"\n",
    "SQL:\n",
    "\"\"\"\n",
    "\n",
    "# Test it\n",
    "# response = client.responses.create(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Delimiters & Structure\n",
    "\n",
    "**Delimiters** clearly separate different parts of your prompt, reducing ambiguity.\n",
    "\n",
    "**Common delimiters:**\n",
    "- Triple quotes: `\"\"\"`\n",
    "- Triple backticks: ` ``` `\n",
    "- XML tags: `<input>`, `<context>`\n",
    "- Markdown headers: `###`\n",
    "- Horizontal rules: `---`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Delimiters (Ambiguous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_delimiters = \"\"\"Summarize this text: The product launch was a success. \n",
    "Sales exceeded expectations by 40%. Customer feedback was overwhelmingly positive.\n",
    "Focus on the key metrics.\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=no_delimiters\n",
    ")\n",
    "\n",
    "print(\"Without delimiters:\")\n",
    "print(response.output_text)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Delimiters (Clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_delimiters = \"\"\"Summarize the text below, focusing on key metrics:\n",
    "\n",
    "###\n",
    "The product launch was a success. Sales exceeded expectations by 40%. \n",
    "Customer feedback was overwhelmingly positive.\n",
    "###\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=with_delimiters\n",
    ")\n",
    "\n",
    "print(\"With delimiters:\")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML-Style Delimiters for Complex Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_structure = \"\"\"<task>\n",
    "Extract the key information and format as JSON.\n",
    "</task>\n",
    "\n",
    "<context>\n",
    "This is a customer support ticket from our CRM system.\n",
    "</context>\n",
    "\n",
    "<input>\n",
    "Customer: Jane Smith\n",
    "Email: jane@example.com\n",
    "Issue: Cannot reset password\n",
    "Priority: High\n",
    "Timestamp: 2025-10-06 14:30:00\n",
    "</input>\n",
    "\n",
    "<output_format>\n",
    "{\n",
    "  \"customer\": \"...\",\n",
    "  \"email\": \"...\",\n",
    "  \"issue\": \"...\",\n",
    "  \"priority\": \"...\",\n",
    "  \"timestamp\": \"...\"\n",
    "}\n",
    "</output_format>\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=xml_structure,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎯 Exercise 5: Using Delimiters\n",
    "\n",
    "**Task:** Rewrite this ambiguous prompt using clear delimiters:\n",
    "\n",
    "> \"Translate this to Swedish: Hello, how are you? Then explain the translation. Also check if the grammar is correct.\"\n",
    "\n",
    "Use XML tags or other delimiters to clearly separate the text to translate, the translation task, and the analysis task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "structured_translation = \"\"\"TODO: Rewrite with clear delimiters\"\"\"\n",
    "\n",
    "# response = client.responses.create(\n",
    "#     model=\"gpt-5-mini\",\n",
    "#     input=structured_translation\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Output Formatting\n",
    "\n",
    "**Structured outputs** ensure consistency and make responses easier to parse programmatically.\n",
    "\n",
    "**Common formats:**\n",
    "- JSON\n",
    "- Markdown tables\n",
    "- CSV\n",
    "- Custom templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Research Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate outline\n",
    "topic = \"The impact of AI on software development\"\n",
    "\n",
    "outline_prompt = f\"\"\"Create a detailed outline for a report on: {topic}\n",
    "\n",
    "Include 3-4 main sections with bullet points for each section.\n",
    "Format as markdown.\n",
    "\"\"\"\n",
    "\n",
    "response_1 = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=outline_prompt\n",
    ")\n",
    "\n",
    "outline = response_1.output_text\n",
    "print(\"Step 1: Generated Outline\")\n",
    "print(outline)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Expand first section\n",
    "expand_prompt = f\"\"\"Based on this outline:\n",
    "\n",
    "{outline}\n",
    "\n",
    "Write a detailed 2-paragraph explanation of the FIRST section only.\n",
    "Use professional tone and include specific examples.\n",
    "\"\"\"\n",
    "\n",
    "response_2 = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=expand_prompt,\n",
    "    previous_response_id=response_1.id  # Chain responses\n",
    ")\n",
    "\n",
    "section_1 = response_2.output_text\n",
    "print(\"Step 2: Expanded First Section\")\n",
    "print(section_1)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Generate conclusion\n",
    "conclusion_prompt = f\"\"\"Based on this report outline and first section:\n",
    "\n",
    "OUTLINE:\n",
    "{outline}\n",
    "\n",
    "FIRST SECTION:\n",
    "{section_1}\n",
    "\n",
    "Write a concise 1-paragraph conclusion that ties together the main points.\n",
    "\"\"\"\n",
    "\n",
    "response_3 = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=conclusion_prompt\n",
    ")\n",
    "\n",
    "conclusion = response_3.output_text\n",
    "print(\"Step 3: Generated Conclusion\")\n",
    "print(conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_feedback = \"\"\"The app is okay I guess. Sometimes it crashes when I upload photos. \n",
    "The UI is pretty confusing tbh. But the filters are cool! Support team is super helpful.\n",
    "Would be nice if it was faster. Overall not bad for a free app.\"\"\"\n",
    "\n",
    "# Step 1: Extract key points\n",
    "extract_prompt = f\"\"\"Extract key points from this user feedback:\n",
    "\n",
    "{raw_feedback}\n",
    "\n",
    "List each point as a bullet with category (Positive/Negative/Neutral).\n",
    "\"\"\"\n",
    "\n",
    "response_extract = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=extract_prompt\n",
    ")\n",
    "\n",
    "key_points = response_extract.output_text\n",
    "print(\"Extracted Key Points:\")\n",
    "print(key_points)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Step 2: Categorize by urgency\n",
    "categorize_prompt = f\"\"\"Based on these feedback points:\n",
    "\n",
    "{key_points}\n",
    "\n",
    "Categorize them by urgency (High/Medium/Low) and suggest priority order for addressing.\n",
    "Format as a table.\n",
    "\"\"\"\n",
    "\n",
    "response_categorize = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=categorize_prompt\n",
    ")\n",
    "\n",
    "categorized = response_categorize.output_text\n",
    "print(\"Categorized by Urgency:\")\n",
    "print(categorized)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Step 3: Generate action items\n",
    "action_prompt = f\"\"\"Based on this prioritized feedback:\n",
    "\n",
    "{categorized}\n",
    "\n",
    "Generate 3 concrete action items for the product team.\n",
    "Format: [Priority] Action - Expected impact\n",
    "\"\"\"\n",
    "\n",
    "response_actions = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=action_prompt\n",
    ")\n",
    "\n",
    "print(\"Action Items:\")\n",
    "print(response_actions.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎯 Exercise 7: Prompt Chaining\n",
    "\n",
    "**Task:** Build a 3-step prompt chain for code review:\n",
    "\n",
    "1. **Identify issues** - Find bugs, code smells, and improvements\n",
    "2. **Prioritize** - Rank issues by severity\n",
    "3. **Generate fixes** - Provide code snippets to fix top 3 issues\n",
    "\n",
    "**Test with this code:**\n",
    "```python\n",
    "def calculate_average(numbers):\n",
    "    total = 0\n",
    "    for i in range(len(numbers)):\n",
    "        total = total + numbers[i]\n",
    "    return total / len(numbers)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "code_to_review = \"\"\"def calculate_average(numbers):\n",
    "    total = 0\n",
    "    for i in range(len(numbers)):\n",
    "        total = total + numbers[i]\n",
    "    return total / len(numbers)\n",
    "\"\"\"\n",
    "\n",
    "# Step 1: Identify issues\n",
    "# TODO: Create prompt\n",
    "\n",
    "# Step 2: Prioritize issues\n",
    "# TODO: Create prompt using output from step 1\n",
    "\n",
    "# Step 3: Generate fixes\n",
    "# TODO: Create prompt using output from step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "✅ **Chain-of-Thought (CoT)**: Step-by-step reasoning for complex problems  \n",
    "✅ **ReAct Pattern**: Combining reasoning with tool use  \n",
    "✅ **Few-Shot Learning**: Guiding behavior with examples  \n",
    "✅ **Delimiters & Structure**: Organizing prompts for clarity  \n",
    "✅ **Prompt Chaining**: Breaking complex tasks into sequential steps  \n",
    "\n",
    "**Key Takeaways:**\n",
    "- CoT improves reasoning quality, especially for math and logic\n",
    "- ReAct is the foundation of agent frameworks (you'll use this in LangGraph!)\n",
    "- Examples are powerful - few-shot > zero-shot for most tasks\n",
    "- Clear structure and delimiters prevent ambiguity\n",
    "- Chaining allows complex workflows with better control\n",
    "\n",
    "**Next Steps:**\n",
    "- Notebook 1.3: Structured Outputs (get reliable, validated data)\n",
    "- Notebook 1.5: Context Management (handle long conversations)\n",
    "- Apply these patterns in LangGraph agents\n",
    "\n",
    "**Resources:**\n",
    "- [Chain-of-Thought Prompting](https://arxiv.org/abs/2201.11903)\n",
    "- [ReAct Paper](https://arxiv.org/abs/2210.03629)\n",
    "- [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}