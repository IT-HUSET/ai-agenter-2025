{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e418e6872e01f651",
   "metadata": {},
   "source": [
    "# 1.0 LangGraph basics\n",
    "\n",
    "Derived from [![LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/) \n",
    "\n",
    "![Screenshot 2024-08-20 at 3.11.22 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dba5f465f6e9a2482ad935_simple-graph1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41be4abe7beb279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install openai~=2.0 --upgrade --quiet\n",
    "%pip install python-dotenv~=1.0 --upgrade --quiet\n",
    "%pip install langchain~=0.3 langchain_openai~=0.3 langgraph~=0.6 langchain_community~=0.3.5 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281c37bc1e618962",
   "metadata": {},
   "source": [
    "### Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e34eb72b2c0a771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check if running in Google Colab\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    IN_COLAB = True\n",
    "    # Get API key from Colab secrets\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
    "    print(\"âœ… Running in Google Colab - API key loaded from secrets\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    # Load from .env file for local development\n",
    "    try:\n",
    "        from dotenv import load_dotenv, find_dotenv\n",
    "        load_dotenv(find_dotenv())\n",
    "        print(\"âœ… Running locally - API key loaded from .env file\")\n",
    "    except ImportError:\n",
    "        print(\"âš ï¸ python-dotenv not installed. Install with: pip install python-dotenv\")\n",
    "\n",
    "# Verify API key is set\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"âŒ OPENAI_API_KEY not found!\")\n",
    "    if IN_COLAB:\n",
    "        print(\"   â†’ Click the key icon (ðŸ”‘) in the left sidebar\")\n",
    "        print(\"   â†’ Add a secret named 'OPENAI_API_KEY'\")\n",
    "        print(\"   â†’ Toggle 'Notebook access' to enable it\")\n",
    "    else:\n",
    "        print(\"   â†’ Create a .env file with: OPENAI_API_KEY=your-key-here\")\n",
    "else:\n",
    "    print(\"âœ… API key configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b87f2c840bc1dc",
   "metadata": {},
   "source": [
    "### Setup models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb48c02167745fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6f0ba5f34e9e47",
   "metadata": {},
   "source": [
    "## Let's get started with LangGraph!\n",
    "\n",
    "Some key concepts in LangGraph are:\n",
    "* [Nodes](https://langchain-ai.github.io/langgraph/concepts/low_level/#nodes)\n",
    "* [Edges](https://langchain-ai.github.io/langgraph/concepts/low_level/#edges)\n",
    "* [State](https://langchain-ai.github.io/langgraph/concepts/low_level/#state)\n",
    "* [START Node](https://langchain-ai.github.io/langgraph/concepts/low_level/#start-node)\n",
    "* [END Node](https://langchain-ai.github.io/langgraph/concepts/low_level/#end-node)\n",
    "* [Conditional Edges](https://langchain-ai.github.io/langgraph/concepts/low_level/#conditional-edges)\n",
    "* [Graph Compilation](https://langchain-ai.github.io/langgraph/concepts/low_level/#compiling-your-graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9584a87f8590d357",
   "metadata": {},
   "source": [
    "## State\n",
    "\n",
    "First, define the [State](https://langchain-ai.github.io/langgraph/concepts/low_level/#state) of the graph. \n",
    "\n",
    "The State schema serves as the input schema for all Nodes and Edges in the graph. All nodes are expected to communicate with that schema.\n",
    "\n",
    "LangGraph offers flexibility in how you define your state schema, accommodating various Python [types](https://docs.python.org/3/library/stdtypes.html#type-objects) and validation approaches!\n",
    "\n",
    "**The main documented way** to specify the schema of a graph is by using `TypedDict`. However, Pydantic BaseModel and dataclasses are also supported. Read more about **[Pydantic state models here](https://langchain-ai.github.io/langgraph/how-tos/state-model/)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbee91078a461365",
   "metadata": {},
   "source": [
    "### TypedDict\n",
    "#### _Simply a dictionary with a fixed set of keys and some typing support. At runtime, itâ€™s still a regular dictionary._\n",
    "\n",
    "We can use the `TypedDict` class from python's `typing` module.\n",
    "\n",
    "It allows you to specify keys and their corresponding value types.\n",
    "\n",
    "But, note that these are type hints. They can used by static type checkers (like [mypy](https://github.com/python/mypy)) or IDEs to catch potential type-related errors before the code is run. But they are not enforced at runtime!\n",
    "\n",
    "```python\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class TypedDictState(TypedDict):\n",
    "    foo: str\n",
    "    bar: str\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce8ff2806a9bb3d",
   "metadata": {},
   "source": [
    "### State with TypedDict\n",
    "Let's go ahead and use the `TypedDict` class from python's `typing` module as our schema, which provides type hints for the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d18a0255b7830e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict, NotRequired\n",
    "\n",
    "class State(TypedDict):\n",
    "    graph_state: str # You can also use optional fields like this: `NotRequired[str]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda679374dd40014",
   "metadata": {},
   "source": [
    "#### Examples of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6285564b000d1446",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_state1: State = {\"graph_state\": \"Hi, this is Zaphod Beeblebrox.\"}\n",
    "\n",
    "# Incorrect use\n",
    "my_state2: State = {\"graph_state\": \"Hi, this is Zaphod Beeblebrox.\", \"age\": 42} # This will result in warning\n",
    "my_state3: State = {} # This will also result in warning\n",
    "\n",
    "\n",
    "# Optional fields\n",
    "class OptionalState(TypedDict):\n",
    "    graph_state: NotRequired[str]\n",
    "\n",
    "my_optional_state1: OptionalState = {} # This will NOT result in warning, as `graph_state` is optional ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20572e3dc5f5020f",
   "metadata": {},
   "source": [
    "## Nodes\n",
    "\n",
    "[Nodes](https://langchain-ai.github.io/langgraph/concepts/low_level/#nodes) are just python functions.\n",
    "\n",
    "The first positional argument is the state, as defined above.\n",
    "\n",
    "Because the state is a `TypedDict` with schema as defined above, each node can access the key, `graph_state`, with `state['graph_state']`.\n",
    "\n",
    "Each node returns a new value of the state key `graph_state`.\n",
    "\n",
    "By default, the new value returned by each node [will override](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) the prior state value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20ded2d9a9b0823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_1(state: State) -> State:\n",
    "    print(\"---Node 1---\")\n",
    "    return {\"graph_state\": state['graph_state'] + \" I am\"}\n",
    "\n",
    "def node_2(state: State) -> State:\n",
    "    print(\"---Node 2---\")\n",
    "    return {\"graph_state\": state['graph_state'] + \" happy!\"}\n",
    "\n",
    "def node_3(state: State) -> State:\n",
    "    print(\"---Node 3---\")\n",
    "    return {\"graph_state\": state['graph_state'] +\" sad!\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2d1bf1fc2afbbe",
   "metadata": {},
   "source": [
    "## Edges\n",
    "\n",
    "[Edges](https://langchain-ai.github.io/langgraph/concepts/low_level/#edges) connect the nodes.\n",
    "\n",
    "Normal Edges are used if you want to *always* go from, for example, `node_1` to `node_2`.\n",
    "\n",
    "[Conditional Edges](https://langchain-ai.github.io/langgraph/reference/graphs/?h=conditional+edge#langgraph.graph.StateGraph.add_conditional_edges) are used want to *optionally* route between nodes.\n",
    " \n",
    "Conditional edges are implemented as functions that return the next node to visit based upon some logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e49519f98b5645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Literal\n",
    "\n",
    "def decide_mood(state) -> Literal[\"node_2\", \"node_3\"]:\n",
    "    \n",
    "    # Often, we will use state to decide on the next node to visit\n",
    "    user_input = state['graph_state'] \n",
    "    \n",
    "    # Here, let's just do a 50 / 50 split between nodes 2, 3\n",
    "    if random.random() < 0.5:\n",
    "\n",
    "        # 50% of the time, we return Node 2\n",
    "        return \"node_2\"\n",
    "    \n",
    "    # 50% of the time, we return Node 3\n",
    "    return \"node_3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9360a968a1a3ffa2",
   "metadata": {},
   "source": [
    "## Graph Construction\n",
    "\n",
    "Now, we build the graph from our [components](\n",
    "https://langchain-ai.github.io/langgraph/concepts/low_level/) defined above.\n",
    "\n",
    "The [StateGraph class](https://langchain-ai.github.io/langgraph/concepts/low_level/#stategraph) is the graph class that we can use.\n",
    " \n",
    "First, we initialize a StateGraph with the `State` class we defined above.\n",
    " \n",
    "Then, we add our nodes and edges.\n",
    "\n",
    "We use the [`START` Node, a special node](https://langchain-ai.github.io/langgraph/concepts/low_level/#start-node) that sends user input to the graph, to indicate where to start our graph.\n",
    " \n",
    "The [`END` Node](https://langchain-ai.github.io/langgraph/concepts/low_level/#end-node) is a special node that represents a terminal node. \n",
    "\n",
    "Finally, we [compile our graph](https://langchain-ai.github.io/langgraph/concepts/low_level/#compiling-your-graph) to perform a few basic checks on the graph structure. \n",
    "\n",
    "We can visualize the graph as a [Mermaid diagram](https://github.com/mermaid-js/mermaid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f09af99c16fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_conditional_edges(\"node_1\", decide_mood)\n",
    "builder.add_edge(\"node_2\", END)\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1adff8bc5fce85e",
   "metadata": {},
   "source": [
    "## Graph Invocation\n",
    "\n",
    "The compiled graph implements the [runnable](https://python.langchain.com/v0.1/docs/expression_language/interface/) protocol.\n",
    "\n",
    "This provides a standard way to execute LangChain components. \n",
    " \n",
    "`invoke` is one of the standard methods in this interface.\n",
    "\n",
    "The input is a dictionary `{\"graph_state\": \"Hi, this is lance.\"}`, which sets the initial value for our graph state dict.\n",
    "\n",
    "When `invoke` is called, the graph starts execution from the `START` node.\n",
    "\n",
    "It progresses through the defined nodes (`node_1`, `node_2`, `node_3`) in order.\n",
    "\n",
    "The conditional edge will traverse from node `1` to node `2` or `3` using a 50/50 decision rule. \n",
    "\n",
    "Each node function receives the current state and returns a new value, which overrides the graph state.\n",
    "\n",
    "The execution continues until it reaches the `END` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf8612e82d6c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"graph_state\" : \"Hi, this is ToBe.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fda55e1705761d3",
   "metadata": {},
   "source": [
    "`invoke` runs the entire graph synchronously.\n",
    "\n",
    "This waits for each step to complete before moving to the next.\n",
    "\n",
    "It returns the final state of the graph after all nodes have executed.\n",
    "\n",
    "In this case, it returns the state after `node_3` has completed: \n",
    "\n",
    "```\n",
    "{'graph_state': 'Hi, this is Lance. I am sad!'}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dd53fba92e24f7",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec081cd55e56cdad",
   "metadata": {},
   "source": [
    "## EXERCISE! Build your own graph\n",
    "\n",
    "**Task:**\n",
    "- Create a graph that takes a name as input, converts it into a cooler sounding name and generates a mood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4865142f8e9c8f",
   "metadata": {},
   "source": [
    "#### Below is a skeleton for the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa4b274eeda551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATE\n",
    "class MyState(TypedDict):\n",
    "    # TODO: Add name and mood\n",
    "    pass # Remove this line\n",
    "\n",
    "# NODES\n",
    "def generate_cool_name(state: MyState) -> MyState:\n",
    "    print(\"---Generate Cool Name---\")\n",
    "    initial_mood = \"ðŸ˜‘\"\n",
    "    new_name = llm.invoke(f\"Generate a cool name based on the name {state['name']}. Answer with just the name.\").content\n",
    "    return {} # TODO: Return the new state\n",
    "\n",
    "def happy_node(state: MyState) -> MyState:\n",
    "    print(\"---Happy Node---\")\n",
    "    return {} # TODO: Return the new state\n",
    "\n",
    "def sad_node(state: MyState) -> MyState:\n",
    "    print(\"---Sad Node---\")\n",
    "    return {} # TODO: Return the new state\n",
    "\n",
    "\n",
    "# EDGES\n",
    "def decide_mood(state: MyState) -> Literal[\"happy_node\", \"sad_node\"]:\n",
    "    name = state['name']\n",
    "    if len(name) % 2 == 0:\n",
    "        return \"happy_node\"\n",
    "    return \"sad_node\"\n",
    "\n",
    "\n",
    "# GRAPH\n",
    "# Configure nodes\n",
    "builder = StateGraph(MyState)\n",
    "builder.add_node(\"generate_cool_name\", generate_cool_name)\n",
    "# TODO: Add missing nodes\n",
    "#builder.add_node(...)\n",
    "#builder.add_node(...)\n",
    "\n",
    "# Configure edges\n",
    "builder.add_edge(START, \"generate_cool_name\")\n",
    "# TODO: Add missing edges\n",
    "#builder.add_conditional_edges()\n",
    "#builder.add_edge(, END)\n",
    "#builder.add_edge(, END)\n",
    "\n",
    "# Compile and view\n",
    "graph = builder.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0b3310dd42513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke\n",
    "graph.invoke({\"name\": \"ToBe\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
