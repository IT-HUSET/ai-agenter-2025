{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1.3: Tool Calling Agent with LangGraph\n",
    "\n",
    "![Tool calling](https://github.com/IT-HUSET/ai-agenter-2025/blob/main/images/tool-calling.png?raw=true)\n",
    "\n",
    "**Objective:** Build a real ReAct agent with tool calling capabilities\n",
    "\n",
    "In this exercise, you'll learn:\n",
    "- Defining tools using `@tool` decorator\n",
    "- Binding tools to LLM with `bind_tools()`\n",
    "- Using `ToolNode` for automatic tool execution\n",
    "- Implementing `tools_condition` for routing\n",
    "- Building a complete ReAct loop\n",
    "\n",
    "<a target=\"_blank\" href=\"https://githubtocolab.com/IT-HUSET/ai-agenter-2025/blob/main/exercises/langgraph/1.3-langgraph-tool-calling.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai~=2.0 --upgrade --quiet\n",
    "%pip install python-dotenv~=1.0 --upgrade --quiet\n",
    "%pip install langchain~=0.3 langchain_openai~=0.3 --upgrade --quiet\n",
    "%pip install langgraph~=0.6 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check if running in Google Colab\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    IN_COLAB = True\n",
    "    # Get API key from Colab secrets\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
    "    print(\"✅ Running in Google Colab - API key loaded from secrets\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    # Load from .env file for local development\n",
    "    try:\n",
    "        from dotenv import load_dotenv, find_dotenv\n",
    "        load_dotenv(find_dotenv())\n",
    "        print(\"✅ Running locally - API key loaded from .env file\")\n",
    "    except ImportError:\n",
    "        print(\"⚠️ python-dotenv not installed. Install with: pip install python-dotenv\")\n",
    "\n",
    "# Verify API key is set\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"❌ OPENAI_API_KEY not found!\")\n",
    "    if IN_COLAB:\n",
    "        print(\"   → Click the key icon (🔑) in the left sidebar\")\n",
    "        print(\"   → Add a secret named 'OPENAI_API_KEY'\")\n",
    "        print(\"   → Toggle 'Notebook access' to enable it\")\n",
    "    else:\n",
    "        print(\"   → Create a .env file with: OPENAI_API_KEY=your-key-here\")\n",
    "else:\n",
    "    print(\"✅ API key configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Define Tools\n",
    "\n",
    "### What are Tools?\n",
    "\n",
    "Tools are functions that an agent can call to:\n",
    "- Access external data (APIs, databases)\n",
    "- Perform calculations\n",
    "- Execute actions (send email, create file)\n",
    "- Interact with systems\n",
    "\n",
    "### The `@tool` Decorator\n",
    "\n",
    "LangChain provides a `@tool` decorator that:\n",
    "1. Converts a Python function into a tool\n",
    "2. Generates a JSON schema from docstring and type hints\n",
    "3. Makes the tool compatible with LLM function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import Literal\n",
    "import random\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the current weather for a city.\n",
    "    \n",
    "    Args:\n",
    "        city: The name of the city to get weather for\n",
    "        \n",
    "    Returns:\n",
    "        A string describing the current weather\n",
    "    \"\"\"\n",
    "    print(f\"🌤️  Calling weather API for: {city}\")\n",
    "    \n",
    "    # Simulated weather data\n",
    "    weather_data = {\n",
    "        \"stockholm\": \"5°C, cloudy with a chance of meatballs\",\n",
    "        \"london\": \"12°C, rainy (as usual)\",\n",
    "        \"tokyo\": \"18°C, clear skies\",\n",
    "        \"new york\": \"8°C, windy\",\n",
    "        \"sydney\": \"25°C, sunny\"\n",
    "    }\n",
    "    \n",
    "    city_lower = city.lower()\n",
    "    if city_lower in weather_data:\n",
    "        return f\"The weather in {city} is: {weather_data[city_lower]}\"\n",
    "    else:\n",
    "        return f\"Weather data not available for {city}. Try Stockholm, London, Tokyo, New York, or Sydney.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression.\n",
    "    \n",
    "    Args:\n",
    "        expression: A mathematical expression as a string (e.g., \"2 + 2\", \"10 * 5\")\n",
    "        \n",
    "    Returns:\n",
    "        The result of the calculation as a string\n",
    "    \"\"\"\n",
    "    print(f\"🔢 Calculating: {expression}\")\n",
    "    \n",
    "    try:\n",
    "        # Safe evaluation (restricted to basic math)\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return f\"The result of {expression} is {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error calculating '{expression}': {str(e)}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_random_fact(topic: Literal[\"space\", \"ocean\", \"animals\", \"history\"]) -> str:\n",
    "    \"\"\"Get a random interesting fact about a topic.\n",
    "    \n",
    "    Args:\n",
    "        topic: The topic to get a fact about (space, ocean, animals, or history)\n",
    "        \n",
    "    Returns:\n",
    "        An interesting fact as a string\n",
    "    \"\"\"\n",
    "    print(f\"📚 Fetching random fact about: {topic}\")\n",
    "    \n",
    "    facts = {\n",
    "        \"space\": [\n",
    "            \"A day on Venus is longer than a year on Venus.\",\n",
    "            \"Neutron stars are so dense that a teaspoon would weigh billions of tons.\",\n",
    "            \"There are more stars in the universe than grains of sand on all Earth's beaches.\"\n",
    "        ],\n",
    "        \"ocean\": [\n",
    "            \"The ocean produces more than 50% of the world's oxygen.\",\n",
    "            \"The deepest part of the ocean is nearly 7 miles down.\",\n",
    "            \"More people have been to the moon than to the deepest part of the ocean.\"\n",
    "        ],\n",
    "        \"animals\": [\n",
    "            \"Octopuses have three hearts and blue blood.\",\n",
    "            \"A group of flamingos is called a 'flamboyance'.\",\n",
    "            \"Honey never spoils. Archaeologists have found 3000-year-old honey that's still edible.\"\n",
    "        ],\n",
    "        \"history\": [\n",
    "            \"Cleopatra lived closer to the Moon landing than to the building of the pyramids.\",\n",
    "            \"Oxford University is older than the Aztec Empire.\",\n",
    "            \"The first programmer was Ada Lovelace in the 1840s.\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return random.choice(facts[topic])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Tools Independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test weather tool\n",
    "print(get_weather.invoke(\"Stockholm\"))\n",
    "print()\n",
    "\n",
    "# Test calculator\n",
    "print(calculate.invoke(\"42 * 17\"))\n",
    "print()\n",
    "\n",
    "# Test fact tool\n",
    "print(get_random_fact.invoke(\"space\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Tool Schema\n",
    "\n",
    "See how LangChain converts your function into a tool schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(\"Weather Tool Schema:\")\n",
    "print(json.dumps(get_weather.args_schema.schema(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 2: Build Tool-Calling Agent with create_react_agent\n\n### The ReAct Pattern\n\n**ReAct** = **Rea**soning + **Act**ing\n\nThe agent follows this loop:\n1. **Think**: Decide what to do based on the question\n2. **Act**: Call a tool if needed\n3. **Observe**: See the tool's result\n4. **Repeat** or **Answer**: Continue until done\n\n### Using create_react_agent\n\nInstead of manually building the graph, LangGraph provides `create_react_agent` which:\n- Automatically binds tools to the LLM\n- Creates the tool execution node\n- Sets up the conditional routing logic\n- Handles the ReAct loop\n\nThis is much simpler than building everything from scratch!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from langgraph.prebuilt import create_react_agent\nfrom IPython.display import Image, display\n\n# Collect all tools\ntools = [get_weather, calculate, get_random_fact]\n\n# Create the agent - that's it! \nagent = create_react_agent(\n    model=llm,\n    tools=tools,\n    prompt=\"You are a helpful assistant with access to tools. Use them when needed to provide accurate information.\"\n)\n\nprint(f\"✅ Created ReAct agent with {len(tools)} tools\")\nprint(f\"   Tools: {[t.name for t in tools]}\")\n\n# Visualize the graph\ndisplay(Image(agent.get_graph(xray=True).draw_mermaid_png()))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### What create_react_agent Does for You\n\nBehind the scenes, `create_react_agent`:\n\n1. **Binds tools to LLM** - Calls `llm.bind_tools(tools)` automatically\n2. **Creates agent node** - Sets up the node that calls the LLM\n3. **Creates ToolNode** - Sets up automatic tool execution\n4. **Adds conditional routing** - Uses `tools_condition` to route between agent and tools\n5. **Builds the graph** - Constructs and compiles the complete StateGraph\n\nThis is the same as what we did manually in Module 1.2, but much simpler!"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Part 3: Test the Agent\n\n### Single Tool Call Test"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from langchain_core.messages import HumanMessage\n\n# Simple question requiring one tool\nquestion = \"What's the weather like in Stockholm?\"\n\nprint(f\"❓ Question: {question}\")\nprint(\"=\"*80)\n\nresult = agent.invoke({\n    \"messages\": [HumanMessage(content=question)]\n})\n\n# Print the conversation\nprint(\"\\n💬 Conversation:\")\nfor msg in result[\"messages\"]:\n    msg.pretty_print()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Multiple Tool Calls Test"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Complex question requiring multiple tools\nquestion = \"Calculate 123 * 456 and also tell me the weather in Tokyo\"\n\nprint(f\"❓ Question: {question}\")\nprint(\"=\"*80)\n\nresult = agent.invoke({\n    \"messages\": [HumanMessage(content=question)]\n})\n\nprint(\"\\n💬 Conversation:\")\nfor msg in result[\"messages\"]:\n    msg.pretty_print()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Chain of Tool Calls Test\n\nTest if the agent can use tool results to make follow-up tool calls:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Question that requires sequential reasoning\nquestion = \"\"\"Calculate 15 * 8, then tell me if that number is greater than 100. \nIf it is, give me a space fact. If not, give me an ocean fact.\"\"\"\n\nprint(f\"❓ Question: {question}\")\nprint(\"=\"*80)\n\nresult = agent.invoke({\n    \"messages\": [HumanMessage(content=question)]\n})\n\nprint(\"\\n💬 Final Answer:\")\nresult[\"messages\"][-1].pretty_print()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Stream the Execution\n\nSee the agent's thought process in real-time:"
  },
  {
   "cell_type": "code",
   "source": "question = \"What's the weather in London and give me a history fact\"\n\nprint(f\"❓ Question: {question}\")\nprint(\"=\"*80)\nprint(\"\\n🔄 Streaming execution:\\n\")\n\nfor step in agent.stream({\"messages\": [HumanMessage(content=question)]}):\n    print(f\"Step: {list(step.keys())[0]}\")\n    print(f\"  Content: {step}\")\n    print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## 🎯 Exercise: Build a Research Assistant Agent\n\n**Challenge:** Create a research assistant using `create_react_agent`.\n\n### Requirements:\n\n1. **Create these tools**:\n   - `search_wikipedia(topic: str)` - Simulate Wikipedia search\n   - `get_current_date()` - Return today's date\n   - `convert_currency(amount: float, from_currency: str, to_currency: str)` - Currency conversion\n\n2. **Build the agent** using `create_react_agent` - just like we did above!\n\n3. **Test with complex queries**:\n   - \"What year was Python created and how many years ago was that?\"\n   - \"Convert 100 USD to EUR and then to JPY\"\n\n### Template",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from datetime import datetime\n\n# TODO: Define your tools here\n@tool\ndef search_wikipedia(topic: str) -> str:\n    \"\"\"Search Wikipedia for information about a topic.\n    \n    Args:\n        topic: The topic to search for\n    \"\"\"\n    # TODO: Implement simulated Wikipedia search\n    wiki_data = {\n        \"python\": \"Python was created by Guido van Rossum and first released in 1991.\",\n        \"langchain\": \"LangChain is a framework for developing LLM applications, created in 2022.\",\n        # Add more topics...\n    }\n    return wiki_data.get(topic.lower(), f\"No information found for {topic}\")\n\n@tool\ndef get_current_date() -> str:\n    \"\"\"Get the current date.\"\"\"\n    # TODO: Return current date in readable format\n    return datetime.now().strftime(\"%Y-%m-%d\")\n\n@tool\ndef convert_currency(amount: float, from_currency: str, to_currency: str) -> str:\n    \"\"\"Convert currency from one type to another.\n    \n    Args:\n        amount: The amount to convert\n        from_currency: Source currency (USD, EUR, JPY, etc.)\n        to_currency: Target currency (USD, EUR, JPY, etc.)\n    \"\"\"\n    # TODO: Implement simulated currency conversion\n    rates = {\n        (\"USD\", \"EUR\"): 0.92,\n        (\"EUR\", \"USD\"): 1.09,\n        (\"USD\", \"JPY\"): 149.50,\n        (\"JPY\", \"USD\"): 0.0067,\n        (\"EUR\", \"JPY\"): 162.50,\n        (\"JPY\", \"EUR\"): 0.0062,\n    }\n    \n    pair = (from_currency.upper(), to_currency.upper())\n    if pair in rates:\n        result = amount * rates[pair]\n        return f\"{amount} {from_currency} = {result:.2f} {to_currency}\"\n    return f\"Conversion rate not available for {from_currency} to {to_currency}\"\n\n# TODO: Create the agent using create_react_agent\n# research_tools = [search_wikipedia, get_current_date, convert_currency]\n# research_agent = create_react_agent(\n#     model=llm,\n#     tools=research_tools,\n#     prompt=\"You are a research assistant...\"\n# )\n\n# TODO: Test with complex queries\n# result = research_agent.invoke({\n#     \"messages\": [HumanMessage(content=\"What year was Python created and how many years ago was that?\")]\n# })\n# result[\"messages\"][-1].pretty_print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## Key Takeaways\n\n✅ **Tool Definition**: Use `@tool` decorator for automatic schema generation  \n✅ **create_react_agent**: Simplifies agent creation with automatic setup  \n✅ **ReAct Pattern**: Think → Act → Observe → Repeat  \n✅ **Simple API**: Just pass model, tools, and prompt to `create_react_agent`  \n✅ **Streaming Support**: Use `.stream()` to see execution in real-time  \n\n### Best Practices for Tool-Calling Agents\n\n**Tool Design:**\n- Clear, descriptive docstrings (LLM reads these!)\n- Type hints for all parameters\n- Meaningful parameter names\n- Handle errors gracefully\n- Return strings (easiest for LLM to process)\n\n**Agent Design:**\n- Use descriptive prompts to guide agent behavior\n- Start simple with a few tools\n- Test tools independently first\n- Use streaming to debug agent reasoning\n\n**Debugging:**\n- Stream execution to see each step\n- Check tool schemas with `.args_schema.schema()`\n- Use `xray=True` in graph visualization\n- Test with increasingly complex queries\n\n### Common Pitfalls\n\n❌ **Poor docstrings** → LLM doesn't know when to use tool  \n❌ **Complex return types** → LLM can't interpret results  \n❌ **No error handling** → Agent gets stuck on failures  \n❌ **Too many tools** → LLM gets confused about which to use  \n❌ **Vague tool names** → LLM calls wrong tool  \n\n### Benefits of create_react_agent vs Manual Construction\n\n**create_react_agent** (Recommended):\n- ✅ Less boilerplate code\n- ✅ Automatically handles common patterns\n- ✅ Easier to maintain\n- ✅ Best for most use cases\n\n**Manual Construction** (Advanced):\n- Use when you need custom node logic\n- Use when you need non-standard routing\n- Use when you need to customize the state schema\n\n### Next Steps\n\n- Explore more complex tool combinations\n- Add memory and persistence to your agents\n- Learn about multi-agent systems\n- Build production-ready agents with error handling\n\n---\n\n## Additional Resources\n\n- [LangGraph create_react_agent Guide](https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/)\n- [LangGraph Agents Overview](https://langchain-ai.github.io/langgraph/agents/agents/)\n- [LangChain Tools Documentation](https://python.langchain.com/docs/concepts/tools/)\n- [ReAct Paper (2022)](https://arxiv.org/abs/2210.03629)",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}