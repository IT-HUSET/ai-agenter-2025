{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5 Building Agentic Applications\n",
    "\n",
    "This notebook shows how to **combine OpenAI's features** to build production-ready AI agents.\n",
    "\n",
    "**Key Topics:**\n",
    "- Web Search tool (real-time information)\n",
    "- File Search tool (RAG with documents)\n",
    "- Multimodal capabilities (images, text)\n",
    "- Advanced streaming patterns\n",
    "- Background mode (long-running tasks)\n",
    "- **Case Study: Research Agent**\n",
    "\n",
    "**Why this matters:** Real agents combine multiple capabilities to solve complex problems.\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/IT-HUSET/ai-agents-course-2025/blob/main/exercises/1.6-agentic-applications.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai~=1.60 python-dotenv~=1.0 pillow requests --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "print(\"\u2705 Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Web Search Tool\n",
    "\n",
    "**Web search** allows your agent to access real-time information from the internet.\n",
    "\n",
    "**Use cases:**\n",
    "- Current events and news\n",
    "- Latest documentation or API changes\n",
    "- Real-time data (stock prices, weather, etc.)\n",
    "- Fact-checking and verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple web search query\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    input=\"What are the latest developments in AI agents as of 2025?\",\n",
    "    tools=[{\"type\": \"web_search\"}]\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting Search Results\n",
    "\n",
    "The response includes metadata about the web searches performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many searches were performed\n",
    "print(f\"Response ID: {response.id}\")\n",
    "print(f\"Model used: {response.model}\")\n",
    "print(f\"\\nOutput items: {len(response.output)}\")\n",
    "\n",
    "# Examine output structure\n",
    "for i, item in enumerate(response.output):\n",
    "    print(f\"\\nItem {i}:\")\n",
    "    print(f\"  Type: {item.type}\")\n",
    "    if hasattr(item, 'content'):\n",
    "        preview = str(item.content)[:100] + \"...\" if len(str(item.content)) > 100 else str(item.content)\n",
    "        print(f\"  Content preview: {preview}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Web Search with Specific Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research question requiring current information\n",
    "research_query = \"\"\"Research and compare the latest versions of LangGraph and LangChain.\n",
    "\n",
    "Please provide:\n",
    "1. Current version numbers\n",
    "2. Major features added in the last 6 months\n",
    "3. Key differences between the two frameworks\n",
    "4. Which one is recommended for building AI agents in 2025?\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    input=research_query,\n",
    "    tools=[{\"type\": \"web_search\"}]\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83c\udfaf Exercise 1: Web Search Agent\n",
    "\n",
    "**Task:** Create a news aggregator agent that:\n",
    "1. Searches for recent news on a given topic\n",
    "2. Summarizes the top 3 stories\n",
    "3. Formats the output as a brief newsletter\n",
    "\n",
    "**Test with topic:** \"GPT-5 release\" or \"AI regulations 2025\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "def create_news_summary(topic: str) -> str:\n",
    "    \"\"\"Generate a news summary on a given topic\"\"\"\n",
    "    # TODO: Create a prompt that searches and summarizes\n",
    "    prompt = f\"\"\"TODO: Write a prompt that:\n",
    "    1. Searches for recent news on: {topic}\n",
    "    2. Finds top 3 most relevant stories\n",
    "    3. Formats as a newsletter with headlines, summaries, and sources\n",
    "    \"\"\"\n",
    "    \n",
    "    # response = client.responses.create(\n",
    "    #     model=\"gpt-5\",\n",
    "    #     input=prompt,\n",
    "    #     tools=[{\"type\": \"web_search\"}]\n",
    "    # )\n",
    "    # return response.output_text\n",
    "    pass\n",
    "\n",
    "# Test it\n",
    "# print(create_news_summary(\"AI regulations 2025\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: File Search Tool\n",
    "\n",
    "**File search** enables RAG (Retrieval-Augmented Generation) with your own documents.\n",
    "\n",
    "**Use cases:**\n",
    "- Q&A over internal documentation\n",
    "- Customer support knowledge bases\n",
    "- Legal document analysis\n",
    "- Research paper summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Files for Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Upload a text file\n",
    "# Note: You'll need to create a sample file first\n",
    "\n",
    "sample_content = \"\"\"# Company Policy: Remote Work\n",
    "\n",
    "## Overview\n",
    "Our company supports flexible remote work arrangements for all employees.\n",
    "\n",
    "## Eligibility\n",
    "- All full-time employees are eligible after 3 months\n",
    "- Part-time employees may request approval from their manager\n",
    "\n",
    "## Equipment\n",
    "- Laptop and monitor provided by IT department\n",
    "- Monthly stipend of $50 for internet expenses\n",
    "- Optional: Standing desk and ergonomic chair (upon request)\n",
    "\n",
    "## Requirements\n",
    "- Available during core hours (10 AM - 3 PM local time)\n",
    "- Respond to messages within 2 hours during business hours\n",
    "- Attend weekly team meetings via video\n",
    "\n",
    "## Security\n",
    "- Use company VPN for all work activities\n",
    "- Keep software up to date\n",
    "- Never share login credentials\n",
    "\"\"\"\n",
    "\n",
    "# Write sample file\n",
    "with open(\"remote_work_policy.txt\", \"w\") as f:\n",
    "    f.write(sample_content)\n",
    "\n",
    "# Upload to OpenAI\n",
    "file = client.files.create(\n",
    "    file=open(\"remote_work_policy.txt\", \"rb\"),\n",
    "    purpose=\"assistants\"  # Required for file search\n",
    ")\n",
    "\n",
    "print(f\"File uploaded: {file.id}\")\n",
    "print(f\"Filename: {file.filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Documents with File Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask questions about the uploaded document\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    input=\"What equipment is provided for remote workers?\",\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"file_search\": {\n",
    "            \"file_ids\": [file.id]\n",
    "        }\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple questions in a conversation\n",
    "questions = [\n",
    "    \"Who is eligible for remote work?\",\n",
    "    \"What are the core hours?\",\n",
    "    \"What security measures are required?\"\n",
    "]\n",
    "\n",
    "previous_id = None\n",
    "\n",
    "for question in questions:\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-5\",\n",
    "        input=question,\n",
    "        tools=[{\n",
    "            \"type\": \"file_search\",\n",
    "            \"file_search\": {\n",
    "                \"file_ids\": [file.id]\n",
    "            }\n",
    "        }],\n",
    "        previous_response_id=previous_id\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nQ: {question}\")\n",
    "    print(f\"A: {response.output_text}\")\n",
    "    \n",
    "    previous_id = response.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83c\udfaf Exercise 2: Document Q&A System\n",
    "\n",
    "**Task:** Create a simple document Q&A system:\n",
    "1. Create a text file with information about a topic (e.g., Python best practices)\n",
    "2. Upload it using the Files API\n",
    "3. Build a function that answers questions about the document\n",
    "4. Test with at least 3 different questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# 1. Create your document content\n",
    "your_document = \"\"\"TODO: Write content about a topic of your choice\"\"\"\n",
    "\n",
    "# 2. Upload the file\n",
    "# TODO: Write file and upload\n",
    "\n",
    "# 3. Create Q&A function\n",
    "def ask_document(question: str, file_id: str) -> str:\n",
    "    \"\"\"Ask a question about the uploaded document\"\"\"\n",
    "    # TODO: Implement\n",
    "    pass\n",
    "\n",
    "# 4. Test with questions\n",
    "# questions = [\n",
    "#     \"Question 1...\",\n",
    "#     \"Question 2...\",\n",
    "#     \"Question 3...\"\n",
    "# ]\n",
    "# for q in questions:\n",
    "#     print(f\"Q: {q}\")\n",
    "#     print(f\"A: {ask_document(q, file_id)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Multimodal Capabilities\n",
    "\n",
    "The Responses API supports **images, text, and audio** in the same conversation.\n",
    "\n",
    "**Use cases:**\n",
    "- Image analysis and description\n",
    "- Visual question answering\n",
    "- Diagram interpretation\n",
    "- Screenshot analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a publicly available image URL\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/1200px-Cat03.jpg\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    input=[\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"Describe this image in detail.\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": image_url}\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Image Analysis with Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze image and search for related information\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    input=[\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"What breed is this cat? Search for information about this breed's characteristics and care requirements.\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": image_url}\n",
    "        }\n",
    "    ],\n",
    "    tools=[{\"type\": \"web_search\"}]\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Images in One Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare multiple images\n",
    "image_1 = \"https://upload.wikimedia.org/wikipedia/commons/3/3a/Cat03.jpg\"\n",
    "image_2 = \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Cat_November_2010-1a.jpg/1200px-Cat_November_2010-1a.jpg\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    input=[\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"Compare these two cat images. What are the differences in appearance?\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": image_1}\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": image_2}\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83c\udfaf Exercise 3: Screenshot Analysis Agent\n",
    "\n",
    "**Task:** Create an agent that analyzes UI screenshots:\n",
    "1. Takes a screenshot URL as input\n",
    "2. Identifies UI elements (buttons, forms, navigation)\n",
    "3. Suggests UX improvements\n",
    "4. Searches for current UI/UX best practices (bonus)\n",
    "\n",
    "**Test with:** Any public screenshot of a web application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "def analyze_ui_screenshot(screenshot_url: str, include_research: bool = False) -> str:\n",
    "    \"\"\"Analyze a UI screenshot and provide feedback\"\"\"\n",
    "    # TODO: Implement\n",
    "    pass\n",
    "\n",
    "# Test with a screenshot URL\n",
    "# screenshot = \"https://example.com/screenshot.png\"\n",
    "# analysis = analyze_ui_screenshot(screenshot, include_research=True)\n",
    "# print(analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Stateful Conversations\n",
    "\n",
    "The Responses API **automatically manages conversation history** using `previous_response_id`.\n",
    "\n",
    "**Benefits:**\n",
    "- No need to manually track messages\n",
    "- Automatic context management\n",
    "- Easy to continue conversations\n",
    "- Built-in context window optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Turn Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a conversation\n",
    "response_1 = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=\"I'm building a web scraper in Python. What libraries should I use?\"\n",
    ")\n",
    "\n",
    "print(\"Turn 1:\")\n",
    "print(response_1.output_text)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue the conversation\n",
    "response_2 = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=\"How do I handle rate limiting?\",\n",
    "    previous_response_id=response_1.id\n",
    ")\n",
    "\n",
    "print(\"Turn 2:\")\n",
    "print(response_2.output_text)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a follow-up that requires context\n",
    "response_3 = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=\"Show me a code example\",\n",
    "    previous_response_id=response_2.id\n",
    ")\n",
    "\n",
    "print(\"Turn 3:\")\n",
    "print(response_3.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Full Conversation History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the entire conversation\n",
    "conversation = client.responses.retrieve(response_id=response_3.id)\n",
    "\n",
    "print(\"Full conversation context:\")\n",
    "print(f\"Response ID: {conversation.id}\")\n",
    "print(f\"Total output items: {len(conversation.output)}\")\n",
    "print(f\"\\nFinal output:\\n{conversation.output_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Manager Helper Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationManager:\n",
    "    \"\"\"Helper class for managing stateful conversations\"\"\"\n",
    "    \n",
    "    def __init__(self, model: str = \"gpt-5-mini\"):\n",
    "        self.model = model\n",
    "        self.last_response_id = None\n",
    "        self.history = []\n",
    "    \n",
    "    def send(self, message: str, **kwargs) -> str:\n",
    "        \"\"\"Send a message and get response\"\"\"\n",
    "        response = client.responses.create(\n",
    "            model=self.model,\n",
    "            input=message,\n",
    "            previous_response_id=self.last_response_id,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        self.last_response_id = response.id\n",
    "        self.history.append({\n",
    "            \"user\": message,\n",
    "            \"assistant\": response.output_text,\n",
    "            \"response_id\": response.id\n",
    "        })\n",
    "        \n",
    "        return response.output_text\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset conversation\"\"\"\n",
    "        self.last_response_id = None\n",
    "        self.history = []\n",
    "    \n",
    "    def get_history(self) -> list:\n",
    "        \"\"\"Get conversation history\"\"\"\n",
    "        return self.history\n",
    "\n",
    "# Test the manager\n",
    "conv = ConversationManager()\n",
    "\n",
    "print(\"Turn 1:\")\n",
    "print(conv.send(\"What's the capital of France?\"))\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"Turn 2:\")\n",
    "print(conv.send(\"What's the population?\"))\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"Turn 3:\")\n",
    "print(conv.send(\"Name 3 famous landmarks\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83c\udfaf Exercise 4: Tutorial Bot\n",
    "\n",
    "**Task:** Build a conversational tutorial bot:\n",
    "1. Teaches a topic step-by-step (e.g., Git basics)\n",
    "2. Asks if the user understands before moving on\n",
    "3. Provides examples when requested\n",
    "4. Remembers what has been covered\n",
    "\n",
    "Use the `ConversationManager` class above as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "class TutorialBot:\n",
    "    \"\"\"Interactive tutorial bot with step-by-step teaching\"\"\"\n",
    "    \n",
    "    def __init__(self, topic: str):\n",
    "        self.topic = topic\n",
    "        self.conv = ConversationManager(model=\"gpt-5\")\n",
    "        # TODO: Initialize with instructions\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"Start the tutorial\"\"\"\n",
    "        # TODO: Implement\n",
    "        pass\n",
    "    \n",
    "    def next_lesson(self):\n",
    "        \"\"\"Move to next lesson\"\"\"\n",
    "        # TODO: Implement\n",
    "        pass\n",
    "    \n",
    "    def ask_question(self, question: str) -> str:\n",
    "        \"\"\"Ask a question about current topic\"\"\"\n",
    "        # TODO: Implement\n",
    "        pass\n",
    "\n",
    "# Test your tutorial bot\n",
    "# bot = TutorialBot(\"Git version control basics\")\n",
    "# bot.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Streaming Responses\n",
    "\n",
    "**Streaming** allows you to display responses as they're generated, improving user experience.\n",
    "\n",
    "**Benefits:**\n",
    "- Lower perceived latency\n",
    "- Better UX for long responses\n",
    "- Can cancel if needed\n",
    "- Real-time feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream a response\n",
    "stream = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=\"Explain how neural networks work in 3 paragraphs\",\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "print(\"Streaming response:\")\n",
    "for chunk in stream:\n",
    "    if hasattr(chunk, 'delta') and hasattr(chunk.delta, 'content'):\n",
    "        print(chunk.delta.content, end='', flush=True)\n",
    "\n",
    "print(\"\\n\\n\u2705 Stream complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming with Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream responses that include web searches\n",
    "stream = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    input=\"What are the latest news about OpenAI?\",\n",
    "    tools=[{\"type\": \"web_search\"}],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "print(\"Streaming with web search:\")\n",
    "for chunk in stream:\n",
    "    if hasattr(chunk, 'delta') and hasattr(chunk.delta, 'content'):\n",
    "        print(chunk.delta.content, end='', flush=True)\n",
    "\n",
    "print(\"\\n\\n\u2705 Stream complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83c\udfaf Exercise 5: Streaming Chat Interface\n",
    "\n",
    "**Task:** Build a simple streaming chat interface:\n",
    "1. Accept user input\n",
    "2. Stream the response with visual indication\n",
    "3. Support multiple turns (use previous_response_id)\n",
    "4. Display \"thinking\" indicator while searching (if using web search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "import time\n",
    "\n",
    "def streaming_chat():\n",
    "    \"\"\"Simple streaming chat interface\"\"\"\n",
    "    # TODO: Implement\n",
    "    pass\n",
    "\n",
    "# Run the chat\n",
    "# streaming_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Instructions Parameter\n",
    "\n",
    "The `instructions` parameter provides **system-level guidance** that persists across the entire conversation.\n",
    "\n",
    "**Use cases:**\n",
    "- Setting agent personality\n",
    "- Defining output format\n",
    "- Establishing constraints\n",
    "- Role definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define persistent instructions\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    instructions=\"\"\"You are a Python expert who:\n",
    "    - Always provides working code examples\n",
    "    - Follows PEP 8 style guidelines\n",
    "    - Explains complex concepts simply\n",
    "    - Includes type hints in all code\n",
    "    \"\"\",\n",
    "    input=\"How do I read a CSV file?\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions Persist Across Turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instructions apply to entire conversation\n",
    "response_1 = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    instructions=\"\"\"You are a technical writer. Always:\n",
    "    1. Use simple language\n",
    "    2. Provide examples\n",
    "    3. Format as markdown\n",
    "    4. Keep responses under 100 words\n",
    "    \"\"\",\n",
    "    input=\"What is a REST API?\"\n",
    ")\n",
    "\n",
    "print(\"Turn 1:\")\n",
    "print(response_1.output_text)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Follow-up inherits instructions\n",
    "response_2 = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=\"What about GraphQL?\",\n",
    "    previous_response_id=response_1.id\n",
    ")\n",
    "\n",
    "print(\"Turn 2 (instructions still apply):\")\n",
    "print(response_2.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83c\udfaf Exercise 6: Code Review Agent\n",
    "\n",
    "**Task:** Build a code review agent with instructions:\n",
    "1. Define clear review criteria in instructions\n",
    "2. Accept code snippets as input\n",
    "3. Provide structured feedback (bugs, style, improvements)\n",
    "4. Support follow-up questions\n",
    "\n",
    "**Test with various code snippets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "REVIEW_INSTRUCTIONS = \"\"\"TODO: Define code review instructions\"\"\"\n",
    "\n",
    "def review_code(code: str, language: str = \"python\") -> str:\n",
    "    \"\"\"Review code and provide feedback\"\"\"\n",
    "    # TODO: Implement\n",
    "    pass\n",
    "\n",
    "# Test code sample\n",
    "sample_code = \"\"\"\n",
    "def get_user(id):\n",
    "    user = database.query(f\"SELECT * FROM users WHERE id = {id}\")\n",
    "    return user\n",
    "\"\"\"\n",
    "\n",
    "# print(review_code(sample_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Advanced Streaming Patterns\n",
    "\n",
    "Streaming with the Responses API uses **semantic events** for fine-grained control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream with event handling\n",
    "print(\"Streaming with events:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "stream = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=\"Write a short poem about coding\",\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for event in stream:\n",
    "    if event.type == \"response.created\":\n",
    "        print(\"\\n\ud83c\udfac Response started\")\n",
    "    elif event.type == \"response.output_text.delta\":\n",
    "        print(event.delta, end=\"\", flush=True)\n",
    "    elif event.type == \"response.completed\":\n",
    "        print(\"\\n\\n\u2705 Response complete\")\n",
    "    elif event.type == \"error\":\n",
    "        print(f\"\\n\u274c Error: {event.error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Tool Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream with web search\n",
    "stream = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=\"What are the latest AI developments in 2025?\",\n",
    "    tools=[{\"type\": \"web_search\"}],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "print(\"Streaming with tool calls:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for event in stream:\n",
    "    if event.type == \"response.web_search.searching\":\n",
    "        print(\"\\n\ud83d\udd0d Searching the web...\")\n",
    "    elif event.type == \"response.output_text.delta\":\n",
    "        print(event.delta, end=\"\", flush=True)\n",
    "    elif event.type == \"response.completed\":\n",
    "        print(\"\\n\\n\u2705 Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Background Mode\n",
    "\n",
    "**Background mode** runs long tasks asynchronously, perfect for reasoning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Background Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Start background task\n",
    "response = client.responses.create(\n",
    "    model=\"o1-mini\",\n",
    "    input=\"Solve this complex math problem step by step: ...\",\n",
    "    background=True\n",
    ")\n",
    "\n",
    "print(f\"Started: {response.id}\")\n",
    "print(f\"Status: {response.status}\")\n",
    "\n",
    "# Poll for completion\n",
    "while response.status in {\"queued\", \"in_progress\"}:\n",
    "    print(f\"\u23f3 Status: {response.status}\")\n",
    "    time.sleep(2)\n",
    "    response = client.responses.retrieve(response.id)\n",
    "\n",
    "if response.status == \"completed\":\n",
    "    print(f\"\\n\u2705 Complete!\")\n",
    "    print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming a Background Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start background + stream\n",
    "stream = client.responses.create(\n",
    "    model=\"o1-mini\",\n",
    "    input=\"Write a detailed analysis of...\",\n",
    "    background=True,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "cursor = None\n",
    "for event in stream:\n",
    "    if event.type == \"response.output_text.delta\":\n",
    "        print(event.delta, end=\"\", flush=True)\n",
    "    cursor = event.sequence_number\n",
    "\n",
    "# If connection drops, resume from cursor:\n",
    "# resumed = client.responses.stream(response_id, starting_after=cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cancelling Background Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start long task\n",
    "response = client.responses.create(\n",
    "    model=\"o3\",\n",
    "    input=\"Very long task...\",\n",
    "    background=True\n",
    ")\n",
    "\n",
    "print(f\"Started: {response.id}\")\n",
    "\n",
    "# Cancel if needed\n",
    "cancelled = client.responses.cancel(response.id)\n",
    "print(f\"Cancelled: {cancelled.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 9: Case Study - Research Agent\n",
    "\n",
    "Let's build a complete research agent that combines:\n",
    "- Web search for current information\n",
    "- File search for stored knowledge\n",
    "- Structured outputs for reliability\n",
    "- Streaming for UX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "class Source(BaseModel):\n",
    "    type: str  # \"web\" or \"document\"\n",
    "    title: str\n",
    "    url: str = None\n",
    "    relevance: float  # 0-1\n",
    "\n",
    "class ResearchFindings(BaseModel):\n",
    "    topic: str\n",
    "    summary: str\n",
    "    key_points: List[str]\n",
    "    sources: List[Source]\n",
    "    confidence: float  # 0-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Research Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchAgent:\n",
    "    \"\"\"Complete research agent combining multiple tools\"\"\"\n",
    "    \n",
    "    def __init__(self, knowledge_files: List[str] = None):\n",
    "        self.knowledge_files = knowledge_files or []\n",
    "    \n",
    "    def research(self, topic: str, stream: bool = False) -> ResearchFindings:\n",
    "        \"\"\"Conduct research on a topic\"\"\"\n",
    "        \n",
    "        # Build tools list\n",
    "        tools = [{\"type\": \"web_search\"}]\n",
    "        \n",
    "        if self.knowledge_files:\n",
    "            tools.append({\n",
    "                \"type\": \"file_search\",\n",
    "                \"file_search\": {\"file_ids\": self.knowledge_files}\n",
    "            })\n",
    "        \n",
    "        # Create prompt\n",
    "        prompt = f\"\"\"Research this topic thoroughly: {topic}\n",
    "        \n",
    "        Use web search for current information and documents for background.\n",
    "        Synthesize findings into a comprehensive report.\n",
    "        \"\"\"\n",
    "        \n",
    "        if stream:\n",
    "            print(\"\ud83d\udd2c Researching...\\n\")\n",
    "            print(\"=\" * 50)\n",
    "            \n",
    "            stream_obj = client.responses.create(\n",
    "                model=\"gpt-4o\",\n",
    "                input=prompt,\n",
    "                tools=tools,\n",
    "                text_format=ResearchFindings,\n",
    "                stream=True\n",
    "            )\n",
    "            \n",
    "            for event in stream_obj:\n",
    "                if event.type == \"response.web_search.searching\":\n",
    "                    print(\"\\n\ud83d\udd0d Searching web...\")\n",
    "                elif event.type == \"response.file_search.searching\":\n",
    "                    print(\"\\n\ud83d\udcc4 Searching documents...\")\n",
    "                elif event.type == \"response.output_text.delta\":\n",
    "                    print(event.delta, end=\"\", flush=True)\n",
    "            \n",
    "            final = stream_obj.get_final_response()\n",
    "            print(\"\\n\" + \"=\" * 50)\n",
    "            return final.output_parsed\n",
    "        else:\n",
    "            response = client.responses.parse(\n",
    "                model=\"gpt-4o\",\n",
    "                input=prompt,\n",
    "                tools=tools,\n",
    "                text_format=ResearchFindings\n",
    "            )\n",
    "            return response.output_parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Use the Research Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent\n",
    "agent = ResearchAgent()\n",
    "\n",
    "# Conduct research\n",
    "findings = agent.research(\n",
    "    \"Latest developments in AI agents as of 2025\",\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "# Display structured results\n",
    "print(\"\\n\\nRESEARCH FINDINGS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Topic: {findings.topic}\")\n",
    "print(f\"\\nSummary: {findings.summary}\")\n",
    "print(f\"\\nKey Points:\")\n",
    "for point in findings.key_points:\n",
    "    print(f\"  \u2022 {point}\")\n",
    "print(f\"\\nSources ({len(findings.sources)}):\")\n",
    "for source in findings.sources[:3]:  # Show top 3\n",
    "    print(f\"  [{source.type}] {source.title}\")\n",
    "print(f\"\\nConfidence: {findings.confidence * 100:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production Considerations\n",
    "\n",
    "When building production agents:\n",
    "\n",
    "**Error Handling:**\n",
    "- Handle refusals gracefully\n",
    "- Retry with exponential backoff\n",
    "- Validate structured outputs\n",
    "\n",
    "**Performance:**\n",
    "- Use streaming for better UX\n",
    "- Use background mode for long tasks\n",
    "- Cache results when appropriate\n",
    "\n",
    "**Monitoring:**\n",
    "- Log all requests/responses\n",
    "- Track token usage\n",
    "- Monitor latency\n",
    "\n",
    "**Security:**\n",
    "- Validate all inputs\n",
    "- Sanitize outputs\n",
    "- Rate limit API calls\n",
    "- Never expose API keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83c\udfaf Exercise 7: Build Your Own Agent\n",
    "\n",
    "**Task:** Extend the research agent with:\n",
    "1. Comparison mode (compare two topics)\n",
    "2. Citation formatting\n",
    "3. Export to markdown\n",
    "4. Error handling and retries\n",
    "\n",
    "**Bonus:** Add support for:\n",
    "- Image analysis\n",
    "- Background mode for deep research\n",
    "- Multiple language support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Extend ResearchAgent class\n",
    "# Add new methods and features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "\u2705 **Web Search Tool**: Access real-time information  \n",
    "\u2705 **File Search Tool**: RAG with your documents  \n",
    "\u2705 **Multimodal Capabilities**: Combine text, images, and more  \n",
    "\u2705 **Advanced Streaming**: Event-driven, tool-aware streaming  \n",
    "\u2705 **Background Mode**: Long-running tasks with polling  \n",
    "\u2705 **Production Agents**: Complete case study with best practices  \n",
    "\n",
    "**Key Takeaways:**\n",
    "- Combine multiple tools for powerful agents\n",
    "- Use streaming for better UX\n",
    "- Background mode for reasoning models\n",
    "- Structured outputs ensure reliability\n",
    "- Handle errors and edge cases\n",
    "- Monitor performance and costs\n",
    "\n",
    "**What's Next:**\n",
    "- Build your own agents!\n",
    "- Explore LangGraph for more complex workflows\n",
    "- Deploy to production with proper monitoring\n",
    "\n",
    "**Resources:**\n",
    "- [Responses API Documentation](https://platform.openai.com/docs/api-reference/responses)\n",
    "- [Web Search Guide](https://platform.openai.com/docs/guides/web-search)\n",
    "- [File Search Guide](https://platform.openai.com/docs/guides/file-search)\n",
    "- [Streaming Guide](https://platform.openai.com/docs/guides/streaming)\n",
    "- [Background Mode Guide](https://platform.openai.com/docs/guides/background-mode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}